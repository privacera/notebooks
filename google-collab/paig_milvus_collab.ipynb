{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uIpXTfSpR5Jw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Privacera AI Governance - Milvus Vector Database Filter\n",
        "\n",
        "This notebook shows how to use Privacera Shield Library with a LangChain application that uses Milvus Vector Database. To run this notebook you will need the following,\n",
        "\n",
        "\n",
        "1.  Sign up for a free account at [Privacera AI Governance (PAIG)](https://privacera.ai). This is simple, all you need is your email address.\n",
        "2.  Your OpenAI API Key. This will allow you to create your first OpenAI application governed by Privacera AI Governance."
      ],
      "metadata": {
        "id": "YQXaxky82t3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Reset a system library and restart the environment"
      ],
      "metadata": {
        "id": "uIpXTfSpR5Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install packaging\n",
        "\n",
        "import subprocess\n",
        "from packaging import version\n",
        "import grpc\n",
        "\n",
        "# Get the current version of grpcio\n",
        "current_version = grpc.__version__\n",
        "print(f\"Current grpcio version: {current_version}\")\n",
        "\n",
        "# Define the version to compare against\n",
        "target_version = version.parse(\"1.63\")\n",
        "\n",
        "# Compare the versions\n",
        "if version.parse(current_version) > target_version:\n",
        "    # Uninstall grpcio if the version is greater than 1.63\n",
        "    subprocess.check_call([\"pip\", \"uninstall\", \"-y\", \"grpcio\"])\n",
        "    print(\"grpcio has been uninstalled.\")\n",
        "    # We need to restart the runtime\n",
        "    # Ignore the warning at the bottom that says the runtime crashed\n",
        "    exit()\n",
        "else:\n",
        "    print(\"grpcio version is not greater than 1.63. No action needed.\")"
      ],
      "metadata": {
        "id": "xUi31CZ4CK47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install the Python packages\n",
        "This will take several seconds, upto a minute."
      ],
      "metadata": {
        "id": "QeU_CKQt3UhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install  \\\n",
        "  milvus \\\n",
        "  pymilvus \\\n",
        "  langchain==0.2.0 \\\n",
        "  langchain-core==0.2.0 \\\n",
        "  langchain-community==0.2.0 \\\n",
        "  langchain-openai==0.1.7 \\\n",
        "  langchain-text-splitters==0.2.0 \\\n",
        "  privacera_shield==1.1.9\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "J5617p25wRX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Start Milvus Vector Database\n",
        "This step will take less than a minute. There could be a few connection errors as Milvus starts, but finally it should say 'Connected to Milvus'"
      ],
      "metadata": {
        "id": "jKg1W2Iv3doC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('milvus-server &')\n",
        "!while ! (ps aux | grep -q '[m]ilvus' && ps aux | grep -q '[m]ilvus-server'); do sleep 1; done; echo 'Milvus is ready'\n",
        "\n",
        "# Replace with your actual Milvus server parameters if different\n",
        "MILVUS_HOST = \"127.0.0.1\"\n",
        "MILVUS_PORT = \"19530\"\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        import time\n",
        "        from pymilvus import connections\n",
        "\n",
        "        connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)\n",
        "        print(\"Connected to Milvus\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"Connection failed: {e}\")\n",
        "        time.sleep(1)"
      ],
      "metadata": {
        "id": "nC7rARxUvEHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Create a Sample Collection in Milvus Vector Database\n",
        "\n",
        "In this step, we will create a sample collection in Milvus Vector Database with\n",
        "following schema -\n",
        "- source - name of the document file\n",
        "- text - content of the document\n",
        "- pk - primary key\n",
        "- vector - embedding vector of the content\n",
        "- users - list of users that have access to this document\n",
        "- groups - list of groups that have access to this document\n",
        "- metadata - additional metadata associated with this document"
      ],
      "metadata": {
        "id": "4f334OlS34pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import CollectionSchema, FieldSchema, DataType\n",
        "\n",
        "COLLECTION_NAME = \"PrivaceraSampleCollection\"\n",
        "\n",
        "def create_collection():\n",
        "    source = FieldSchema(\n",
        "        name=\"source\",\n",
        "        dtype=DataType.VARCHAR,\n",
        "        max_length=65535\n",
        "    )\n",
        "    text = FieldSchema(\n",
        "        name=\"text\",\n",
        "        dtype=DataType.VARCHAR,\n",
        "        max_length=65535\n",
        "    )\n",
        "    pk = FieldSchema(\n",
        "        name=\"pk\",\n",
        "        dtype=DataType.INT64,\n",
        "        is_primary=True,\n",
        "        auto_id=True\n",
        "    )\n",
        "    vector = FieldSchema(\n",
        "        name=\"vector\",\n",
        "        dtype=DataType.FLOAT_VECTOR,\n",
        "        dim=1536\n",
        "    )\n",
        "    users = FieldSchema(\n",
        "        name=\"users\",\n",
        "        dtype=DataType.ARRAY,\n",
        "        element_type=DataType.VARCHAR,\n",
        "        max_length=65535,\n",
        "        max_capacity=1024\n",
        "    )\n",
        "    groups = FieldSchema(\n",
        "        name=\"groups\",\n",
        "        dtype=DataType.ARRAY,\n",
        "        element_type=DataType.VARCHAR,\n",
        "        max_length=65535,\n",
        "        max_capacity=1024\n",
        "    )\n",
        "    metadata = FieldSchema(\n",
        "        name=\"metadata\",\n",
        "        dtype=DataType.JSON\n",
        "    )\n",
        "\n",
        "    schema = CollectionSchema(\n",
        "        fields=[source, text, pk, vector, users, groups, metadata],\n",
        "        description=\"Sample Privacera Milvus Collection\",\n",
        "        enable_dynamic_field=True\n",
        "    )\n",
        "\n",
        "    from pymilvus import connections\n",
        "    connections.connect(\n",
        "        alias=\"default\",\n",
        "        host=MILVUS_HOST,\n",
        "        port=MILVUS_PORT\n",
        "    )\n",
        "\n",
        "    from pymilvus import Collection\n",
        "\n",
        "    collection = Collection(\n",
        "        name=COLLECTION_NAME,\n",
        "        schema=schema,\n",
        "        using='default'\n",
        "    )\n",
        "\n",
        "    from pymilvus import Collection\n",
        "\n",
        "    collection = Collection(COLLECTION_NAME)\n",
        "\n",
        "    index_params = {\n",
        "        \"index_type\": \"HNSW\",\n",
        "        \"metric_type\": \"L2\",\n",
        "        \"params\": {\n",
        "            \"M\": 10,\n",
        "            \"efConstruction\": 8\n",
        "        }\n",
        "    }\n",
        "\n",
        "    collection.create_index(\n",
        "        field_name=\"vector\",\n",
        "        index_params=index_params,\n",
        "        index_name=\"index\"\n",
        "    )\n",
        "    print(f\"Collection = {COLLECTION_NAME} created\")\n",
        "\n",
        "create_collection()"
      ],
      "metadata": {
        "id": "ba14MlnNwRFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Create sample documents in a folder\n",
        "\n",
        "Creating some sample documents in a folder named raw_data.\n",
        "\n",
        "- x10.txt - Contains existing product specification.\n",
        "- x11.txt - Contains the specification of the product which is under development. This is highly classified data.\n",
        "- x10-salesdata.txt - Sales number for the product x10. Only Sales team have access to it.\n",
        "- customer-feedback.txt - Customer feedback which contains PII data. Only few people can access see PII data"
      ],
      "metadata": {
        "id": "rEVwLIFyMMPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def create_raw_data():\n",
        "    raw_data_dir = \"raw_data\"\n",
        "\n",
        "    file_contents = {\n",
        "        \"x10.txt\": \"\"\"\n",
        "Product Specification Sheet of x10\n",
        "Display: Size and resolution - 6.5\" AMOLED, 120Hz refresh rate\n",
        "Processor: Model name  Snapdragon 8 Gen 1\n",
        "RAM: Options 8GB/12GB\n",
        "Storage: Options 128GB/256GB\n",
        "Camera: rear camera system with multiple lenses, front-facing camera\n",
        "Battery: Capacity 5000mAh\n",
        "Operating System: Version Android 13\n",
        "Key Features: long battery life, fast performance, high-quality camera\n",
        "        \"\"\"\n",
        "        , \"x11.txt\": \"\"\"\n",
        "Product Specification Sheet of x11\n",
        "Display: Size and resolution - 7.5\" AMOLED, 360Hz refresh rate\n",
        "Processor: Model name  Snapdragon 10 Gen 3\n",
        "RAM: Options 16GB/24GB\n",
        "Storage: Options 256GB/512GB\n",
        "Camera: 360 camera system with multiple lenses, front-facing camera\n",
        "Battery: Capacity 10000mAh\n",
        "Operating System: Version Android 13\n",
        "Key Features: super long battery life, ultra fast performance, 360 camera\n",
        "        \"\"\"\n",
        "        , \"x10-salesdata.txt\": \"\"\"\n",
        "Sales Data for X10 Model:\n",
        "Monthly Sales Report (Internal)\n",
        "Region\tUnits Sold\tRevenue\n",
        "North America\t20,000\t$10,000,000\n",
        "Europe\t15,000\t$7,500,000\n",
        "Asia Pacific\t10,000\t$5,000,000\n",
        "Total\t45,000\t$22,500,000\n",
        "    \"\"\"\n",
        "        , \"customer-feedback.txt\": \"\"\"\n",
        "Customer Feedback Analysis - X10 Model\n",
        "\n",
        "Positive Feedback for X10 Model:\n",
        "\n",
        "\"The X10's battery life is amazing! I can finally ditch the portable charger.\"\n",
        "\n",
        "Sarah Jones, Busy Professional\n",
        "Email: sarah.jones@samplemail.com\n",
        "Phone: (123) 456-7890\n",
        "\"The camera takes crystal-clear pictures, even in low-light conditions. Perfect for capturing memories on the go!\"\n",
        "\n",
        "David Lee, Travel Blogger\n",
        "Email: david.lee@travelblogger.com\n",
        "Phone: (234) 567-8901\n",
        "\"The phone's design is sleek and feels luxurious in hand. The user interface is user-friendly and easy to navigate, even for non-tech-savvy users like me.\"\n",
        "\n",
        "Emily Garcia, Teacher\n",
        "Email: emily.garcia@schoolmail.com\n",
        "Phone: (345) 678-9012\n",
        "\n",
        "Areas for Improvement for X10 Model:\n",
        "\n",
        "\"The phone is a bit bulky for one-handed use. It can be challenging to reach the top of the screen comfortably.\"\n",
        "\n",
        "Michael Chen, Gamer\n",
        "Email: michael.chen@gamermail.com\n",
        "Phone: (456) 789-0123\n",
        "\"I've encountered a few minor software bugs that require restarting the phone. Hopefully, future updates will address these.\"\n",
        "\n",
        "Olivia Rodriguez, Social Media Manager\n",
        "Email: olivia.rodriguez@socialhub.com\n",
        "Phone: (567) 890-1234\n",
        "\"The current storage options are a bit limiting for someone who stores a lot of photos and videos. A higher storage tier or microSD card support would be ideal.\"\n",
        "\n",
        "William Smith, Content Creator\n",
        "Email: william.smith@creatorhub.com\n",
        "Phone: (678) 901-2345\n",
        "\n",
        "Feature Requests for X10 Model:\n",
        "\n",
        "\"Wireless charging would be a fantastic addition for convenience. No more fumbling with cables!\" (Multiple Users)\n",
        "\"A built-in fingerprint sensor would be a welcome security feature for added peace of mind.\" (Several Users)\n",
        "\"The ability to expand storage with a microSD card would be incredibly helpful for users who need more space.\" (Content Creators & Photographers)\n",
        "\"\"\"\n",
        "    }\n",
        "\n",
        "    os.makedirs(raw_data_dir, exist_ok=True)\n",
        "\n",
        "    for file_path, content in file_contents.items():\n",
        "        file_path_with_dir = raw_data_dir + \"/\" + file_path\n",
        "        with open(file_path_with_dir, 'w') as file:\n",
        "            file.write(content)\n",
        "\n",
        "    print(\"Raw data created successfully.\")\n",
        "\n",
        "\n",
        "create_raw_data()"
      ],
      "metadata": {
        "id": "Axt8H7F2Mu9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Associate metadata with the documents\n",
        "Here, we create a custom loader class that will add additional metadata for each *document* in the collection. For each document, we have list of users who are allowed to access the document, a list of groups that are allowed to access the document and additional metadata such as location (country) associated with the document.\n",
        "\n",
        "We will use the users, groups and country attribute to filter the documents based upon the user querying the vector database."
      ],
      "metadata": {
        "id": "mPwRbVwo4hKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from typing import Optional, List, Iterator\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Define raw data metadata information\n",
        "file_metadata = {\n",
        "    \"x10.txt\": {\n",
        "        \"users\": [\"sally\", \"peter\", \"emily\", \"mark\"],\n",
        "        \"groups\": [],\n",
        "        \"metadata\": {\"file_name\": \"x10.txt\"}\n",
        "    },\n",
        "    \"x11.txt\": {\n",
        "        \"users\": [\"mark\", \"peter\"],\n",
        "        \"groups\": [],\n",
        "        \"metadata\": {\"SECURITY_LEVEL\": \"CONFIDENTIAL\", \"file_name\": \"x11.txt\"}\n",
        "    },\n",
        "    \"x10-salesdata.txt\": {\n",
        "        \"users\": [\"sally\"],\n",
        "        \"groups\": [\"Sales\"],\n",
        "        \"metadata\": {\"file_name\": \"x10-salesdata.txt\"}\n",
        "    },\n",
        "    \"customer-feedback.txt\": {\n",
        "        \"users\": [\"emily\", \"sally\", \"peter\", \"mark\"],\n",
        "        \"groups\": [\"Sales\"],\n",
        "        \"metadata\": {\"file_name\": \"customer-feedback.txt\"}\n",
        "    }\n",
        "}\n",
        "\n",
        "class PrivaceraTextLoader(TextLoader):\n",
        "    def __init__(self, file_path: str, encoding: Optional[str] = None, autodetect_encoding: bool = False):\n",
        "        super().__init__(file_path, encoding, autodetect_encoding)\n",
        "        print(f\"inside CustomTextLoader init, file_path={file_path}\")\n",
        "\n",
        "    def lazy_load(self) -> Iterator[Document]:\n",
        "        documents = super().lazy_load()\n",
        "\n",
        "        for doc in documents:\n",
        "            file_name = os.path.basename(self.file_path)\n",
        "            print(f\"lazy_load: file_name={file_name}\")\n",
        "            metadata = file_metadata.get(file_name)\n",
        "            if metadata:\n",
        "              doc.metadata[\"users\"] = file_metadata[file_name][\"users\"]\n",
        "              doc.metadata[\"groups\"] = file_metadata[file_name][\"groups\"]\n",
        "              doc.metadata[\"metadata\"] = file_metadata[file_name][\"metadata\"]\n",
        "\n",
        "            yield doc\n",
        "\n",
        "print(\"PrivaceraTextLoader is ready\")\n"
      ],
      "metadata": {
        "id": "zxNRHlzXOHpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Set your OpenAI API key in the environment\n",
        "Enter your OpenAI API key so that it is set in the environment. This key will not be uploaded to Privacera AI Governance service."
      ],
      "metadata": {
        "id": "GVfBrEBp5M3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "#if os.environ.get(\"OPENAI_API_KEY\") is None:\n",
        "openai_api_key = getpass(\"ðŸ”‘ Enter your OpenAI API key and hit Enter:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "GK7ihmtux6rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Load the sample documents into Milvus vector database\n",
        "Now the sample documents are loaded into Milvus vector database using LangChain and OpenAI embedding API."
      ],
      "metadata": {
        "id": "iCw3ApSy7F1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.milvus import Milvus\n",
        "\n",
        "text_loader_kwargs = {'autodetect_encoding': True}\n",
        "loader = DirectoryLoader(\"raw_data\", glob=\"**/*.txt\",\n",
        "                         loader_cls=PrivaceraTextLoader,\n",
        "                         loader_kwargs=text_loader_kwargs)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"len docs = {len(docs)}\")\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(docs)\n",
        "\n",
        "# Create OpenAI Embeddings\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "vector_store = Milvus.from_documents(\n",
        "    docs,\n",
        "    embedding=embeddings,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT}\n",
        ")\n",
        "\n",
        "print(\"Loaded data into collection successfully.\")"
      ],
      "metadata": {
        "id": "PHs_9nJtxj8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Create Privacera AI Application and the VectorDB configuration\n",
        "\n",
        "In this step, we will create an AI Application configuration in PAIG that will be used to associate PAIG with a sample RAG Langchain application.\n",
        "\n",
        "1. Log into your account in PAIG.\n",
        "1. Click on Application -> Vector DB and create a Vector DB and name it **Product Catalog - Milvus**, and save it.\n",
        "1. Navigate back to the Application -> AI Application and create a new application and call it **Product Catalog - Milvus**\n",
        "1. By clicking the **DOWNLOAD APP CONFIG**, download your application configuration file to your local disk.\n",
        "1. Click on the pencil icon in the Information panel, and then click on the Enabled toggle to enable it, and then click on the Associated VectorDB drop-down and select the **Product Catalog - Milvus** vector database, and then click on Save in the application panel."
      ],
      "metadata": {
        "id": "nyRmcSxp5ePx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Upload the PAIG Application Config file to Colab\n",
        "\n",
        "Run the cell and click on the **Choose Files** button. Select the application config file from your local disk and it will be uploaded into Colab."
      ],
      "metadata": {
        "id": "763yI6h1WB75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "files = uploaded.keys()\n",
        "if len(files) > 1:\n",
        "  print(\"Upload only the application config json file\")\n",
        "else:\n",
        "  app_config_file_content = uploaded[list(files)[0]].decode('UTF-8')"
      ],
      "metadata": {
        "id": "DSsAuPhh2CE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. LangChain RAG bot\n",
        "We have implemented a small RAG bot using LangChain that will use the Milvus vector database to provide the context.\n"
      ],
      "metadata": {
        "id": "R7H1naA_8kU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import privacera_shield\n",
        "from privacera_shield import client as privacera_shield_client\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=3)\n",
        "\n",
        "# Create Milvus vector store\n",
        "vector_store = Milvus(embeddings, COLLECTION_NAME,\n",
        "                      connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT})\n",
        "\n",
        "# expose this index in a retriever interface\n",
        "milvus_retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity\", search_kwargs={\"k\": 100}\n",
        ")\n",
        "\n",
        "# Initialize Privacera Shield\n",
        "privacera_shield_client.setup(frameworks=[\"milvus\", \"langchain\"], application_config=app_config_file_content)\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=openai_api_key, model_name=\"gpt-3.5-turbo\")\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "\n",
        "def query_as_user(username, query):\n",
        "    print(f\"Prompt: {query}\")\n",
        "    print()\n",
        "\n",
        "    llm_chain = ConversationalRetrievalChain.from_llm(llm=llm,\n",
        "                                                      retriever=milvus_retriever,\n",
        "                                                      memory=memory,\n",
        "                                                      verbose=False)\n",
        "    try:\n",
        "        with privacera_shield_client.create_shield_context(username=username):\n",
        "            response = llm_chain.invoke({\"question\": query})\n",
        "            print(\"LLM Response:\")\n",
        "            print(f\"{response.get('answer')}\")\n",
        "            #wrap_text(f\"{response.get('answer')}\")\n",
        "    except privacera_shield.exception.AccessControlException as e:\n",
        "        # If access is denied, then this exception will be thrown. You can handle it accordingly.\n",
        "        print(f\"AccessControlException: {e}\")\n",
        "\n",
        "# utility function to wrap the output\n",
        "def wrap_text(text, width=80):\n",
        "    words = text.split()\n",
        "    character_count = 0\n",
        "    for word in words:\n",
        "        if character_count + len(word) + 1 > width:  # Check if adding the word would exceed the width\n",
        "            print(\"\\n\", end=\"\")  # Start a new line\n",
        "            character_count = 0  # Reset the character count for the new line\n",
        "        print(word, end=\" \")  # Print the word followed by a space\n",
        "        character_count += len(word) + 1  # Update the character count\n",
        "\n",
        "print(\"RAG Bot is ready\")"
      ],
      "metadata": {
        "id": "BVBorz6S1mNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Create users in PAIG portal\n",
        "\n",
        "1. Click on Account -> User Management and click on Add User button\n",
        "1. Enter First Name as mark, Last Name as mark, User Name as mark and select Role as User and save the user.\n",
        "1. Similarly create users sally, emily and peter"
      ],
      "metadata": {
        "id": "-SX_ybD7U1If"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Ask question about the product X11 which is under development\n",
        "\n",
        "\n",
        "Peter belongs to the R&D team and has access to details of unreleased product called X11. And he should be able to compare all the phone models.\n",
        "\n",
        "Sally belongs to the Sales team and she doesn't have access to details of X11 and she shouldn't be able to compare the phone models\n",
        "\n",
        "Since the Product Development of X11 is marked as CONFIDENTIAL, only certain users have access to it."
      ],
      "metadata": {
        "id": "KnprAOe9Xrwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"peter\", \"Compare the product specifications for X10 and X11\")\n",
        "# this will compare both the product names"
      ],
      "metadata": {
        "id": "Gz-DFLGRQ0l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"sally\", \"Compare the product specifications for X10 and X11\")\n",
        "# since Sally doesn't have access to new development, she won't be able to compare the models"
      ],
      "metadata": {
        "id": "bpW7i6vgX5xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Ask sales details by members of Sales and other teams\n",
        "\n",
        "Sally belongs to the Sales team and she has access to the sales numbers.\n",
        "\n",
        "Peter belonging to the R&D doesn't have access sales data.\n",
        "\n",
        "Only the sales team has access to sales documents and these are carried forward in the VectorDB and enforced there"
      ],
      "metadata": {
        "id": "n3AD3UIMYAGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"sally\", \"Give me the monthly sales data for X10?\")"
      ],
      "metadata": {
        "id": "IqGwjVtpYEJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"peter\", \"Give me the monthly sales data for X10?\")"
      ],
      "metadata": {
        "id": "oIMtUmjBYDoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Let's redact PII data based on policy\n",
        "Sally belongs to the Sales team and she can see customer details\n",
        "\n",
        "Peter belonging to the R&D can't see customer PII data, but can see the feedback.\n",
        "\n",
        "1. Go to **Application -> AI Applications** and select the **AI Application** you created\n",
        "2. Now select the **PERMISSIONS** tab\n",
        "3. Click the pencil for the **Personal Identifier Redaction** policy\n",
        "1. Remove **Everyone** and add **peter**\n",
        "1. On the right side for **Prompt** select the dropdown value **Allow**\n",
        "1. Leave the **Reply** as **Redact**\n",
        "1. Save the policy\n",
        "1. Now **Enable** the policy by toggling **Status** toggle\n"
      ],
      "metadata": {
        "id": "nRxE9xY0YJaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"sally\", \"Give me the customer feedbacks and their contact information\")"
      ],
      "metadata": {
        "id": "W37s1s63YV_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"peter\", \"Give me the customer feedbacks and their contact information\")"
      ],
      "metadata": {
        "id": "_3CDgb7dYX86"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}