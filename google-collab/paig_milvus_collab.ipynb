{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Privacera AI Governance - Milvus Vector Database Filter\n",
        "\n",
        "This notebook shows how to use Privacera Shield Library with a LangChain application that uses Milvus Vector Database. To run this notebook you will need the following,\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1.  Sign up for a free account at [Privacera AI Governance (PAIG)](https://privacera.ai). This is simple, all you need is your email address.\n",
        "2.  Your OpenAI API Key. This will allow you to create your first OpenAI application governed by Privacera AI Governance.\n",
        "\n",
        "## Details\n",
        "\n",
        "This notebook does the following:\n",
        "\n",
        "1. Installs Milvus and runs the server within Google Colab.\n",
        "2. Creates a VectorDB collection called PrivaceraSampleCollection with the required columns for Vector Search and PAIG's access controls.\n",
        "3. Generates sample documents and associates the access permissions and classifications for these documents.\n",
        "4. Using LangChain, embeddings are created and stored in VectorDB along with access control permissions and classifications from the original documents.\n",
        "4. Sets up the GenAI application and VectorDB in the PAIG portal.\n",
        "5. Writes a GenAI application using LangChain, which uses Milvus as VectorDB and PAIG for Safety, Security, and Observability.\n",
        "6. Tries out various use cases to ensure that data leakage doesn't happen.\n"
      ],
      "metadata": {
        "id": "YQXaxky82t3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Reset grpcio system library and restart the environment\n",
        "\n",
        "The grpcio that is bundled with Google Collab has some incompatibility with Milvus. We need to uninstall it and restart the runtime.\n"
      ],
      "metadata": {
        "id": "uIpXTfSpR5Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install packaging\n",
        "\n",
        "import subprocess\n",
        "from packaging import version\n",
        "import grpc\n",
        "\n",
        "# Get the current version of grpcio\n",
        "current_version = grpc.__version__\n",
        "print(f\"Current grpcio version: {current_version}\")\n",
        "\n",
        "# Define the version to compare against\n",
        "target_version = version.parse(\"1.63\")\n",
        "\n",
        "# Compare the versions\n",
        "if version.parse(current_version) > target_version:\n",
        "    print(f\"grpcio version is {version.parse(current_version)} which is greater than {target_version}, so uninstalling it\")\n",
        "    # Uninstall grpcio if the version is greater than 1.63\n",
        "    subprocess.check_call([\"pip\", \"uninstall\", \"-y\", \"grpcio\"])\n",
        "    print(\"grpcio has been successfully uninstalled.\")\n",
        "    print(\"Restarting runtime. No action needed from your side!!!\")\n",
        "    # We need to restart the runtime\n",
        "    # Ignore the warning at the bottom that says the runtime crashed\n",
        "    exit()\n",
        "else:\n",
        "    print(\"grpcio version is not greater than 1.63. No action needed.\")"
      ],
      "metadata": {
        "id": "xUi31CZ4CK47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b95b1a-67b8-4127-a72d-1889894fe37e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (24.1)\n",
            "Current grpcio version: 1.64.1\n",
            "grpcio version is 1.64.1 which is greater than 1.63, so uninstalling it\n",
            "grpcio has been successfully uninstalled.\n",
            "Restarting runtime. No action needed from your side!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install the Python packages\n",
        "This will take several seconds, upto a minute. This installs LangChain, Milvus and PAIG"
      ],
      "metadata": {
        "id": "QeU_CKQt3UhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install  \\\n",
        "  milvus \\\n",
        "  pymilvus \\\n",
        "  langchain==0.2.0 \\\n",
        "  langchain-core==0.2.0 \\\n",
        "  langchain-community==0.2.0 \\\n",
        "  langchain-openai==0.1.7 \\\n",
        "  langchain-text-splitters==0.2.0 \\\n",
        "  privacera_shield==1.1.9\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "J5617p25wRX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc390469-d181-492f-b8c9-774031c586a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Set your OpenAI API key in the environment\n",
        "Enter your OpenAI API key so that it is set in the environment. This key will be stored in the memory and won't be uploaded to PAIG portal or used by PAIG components."
      ],
      "metadata": {
        "id": "GVfBrEBp5M3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "#if os.environ.get(\"OPENAI_API_KEY\") is None:\n",
        "openai_api_key = getpass(\"🔑 Enter your OpenAI API key and hit Enter:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "GK7ihmtux6rI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9220c209-bab0-484a-da9a-3c2eacc08b88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔑 Enter your OpenAI API key and hit Enter:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Create Privacera AI Application and the VectorDB configuration\n",
        "\n",
        "In this step, we will create an AI Application configuration in PAIG that will be used to associate PAIG with a sample RAG Langchain application.\n",
        "\n",
        "1. Log into your PAIG account to configure VectorDB and GenAI applcation\n",
        "1. **Add VectorDB in PAIG**: Click on Application -> Vector DB and create a Vector DB and name it **Product Catalog - Milvus**, and save it. Note: This only adds the reference in PAIG. You still need to configure and start Vector, which is done in subsequent steps\n",
        "1. **Enable User/Groups Access Control**: Go to the **Permissions** tab and click on the **pencil** icon and toggle **User/Group Access-Limited Retrieval** to enable it. Save after toggling it. This enforce document level access control while retrieving embeddings from VectorDB\n",
        "1. **Add GenAI Application in PAIG**: Navigate back to the Application -> AI Application and create a new application and call it **Product Catalog - Milvus**\n",
        "1. **Associate VectorDB with GenAI Application**: Click on the Associated VectorDB drop-down and select the **Product Catalog - Milvus** vector database, and then click on the **Create** button.\n",
        ">If you missed associating VectorDB while creating GenAI application, then associate it by clicking on the pencil icon in the Information panel, and then click on the Enabled toggle to enable it, and then select the **Product Catalog - Milvus** vector database, and then click on the **Save** button.\n",
        "1. **Download Config File**: By clicking the **DOWNLOAD APP CONFIG**, download your application configuration file to your local disk.\n",
        "> By default, it is generally saved in the Downloads folder of your laptop\n"
      ],
      "metadata": {
        "id": "nyRmcSxp5ePx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Upload the PAIG Application Config file to Colab\n",
        "\n",
        "Your GenAI application will need the configuration file you downloaded from PAIG. You need to upload it to the Collab instance by running this cell and clicking on the **Choose Files** button. Select the application config file from your local disk and it will be uploaded into Colab. This configuration file is used when PAIG initializes for the first time in your GenAI application\n",
        "\n",
        "> Generally the file will downloaded with the name privacera-shield-Product-Catalog---Milvus-config.json"
      ],
      "metadata": {
        "id": "763yI6h1WB75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "files = uploaded.keys()\n",
        "if len(files) > 1:\n",
        "  print(\"Upload only the application config json file\")\n",
        "else:\n",
        "  app_config_file_content = uploaded[list(files)[0]].decode('UTF-8')"
      ],
      "metadata": {
        "id": "DSsAuPhh2CE2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "23020032-b26c-4fbc-d2ef-676d8ceeecdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dc7f7223-fe9b-4bb9-a04c-44dc8a9cdfec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dc7f7223-fe9b-4bb9-a04c-44dc8a9cdfec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving privacera-shield-Product-Catalog---Milvus-1-config.json to privacera-shield-Product-Catalog---Milvus-1-config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Start Milvus Vector Database\n",
        "This step will start Milvus within the Collab. It should take less than a minute. There could be a few connection errors as Milvus starts, but finally it should say 'Connected to Milvus'\n",
        "> Ignore errors like `Connection failed: [Errno 2] No such file or directory: '/usr/local/lib/python3.10/dist-packages/packaging-24.1.dist-info/METADATA'`\n"
      ],
      "metadata": {
        "id": "jKg1W2Iv3doC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('milvus-server &')\n",
        "!while ! (ps aux | grep -q '[m]ilvus' && ps aux | grep -q '[m]ilvus-server'); do sleep 1; done; echo 'Milvus is ready'\n",
        "\n",
        "# Replace with your actual Milvus server parameters if different\n",
        "MILVUS_HOST = \"127.0.0.1\"\n",
        "MILVUS_PORT = \"19530\"\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        import time\n",
        "        from pymilvus import connections\n",
        "\n",
        "        connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)\n",
        "        print(\"Connected to Milvus\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"Connection failed: {e}\")\n",
        "        time.sleep(1)"
      ],
      "metadata": {
        "id": "nC7rARxUvEHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5931d954-95bf-4030-ceb2-3242e91ac36a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Milvus is ready\n",
            "Connection failed: [Errno 2] No such file or directory: '/usr/local/lib/python3.10/dist-packages/packaging-24.1.dist-info/METADATA'\n",
            "Connected to Milvus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Create Collection in Milvus Vector Database for GenAI Application\n",
        "\n",
        "In this step, we will create a collection in Milvus Vector Database with\n",
        "following schema -\n",
        "- source - name of the document file\n",
        "- text - content of the document\n",
        "- pk - primary key\n",
        "- vector - embedding vector of the content\n",
        "- users - list of users that have access to this document\n",
        "- groups - list of groups that have access to this document\n",
        "- metadata - additional metadata associated with this document\n",
        "\n",
        "> The columns **users**, **groups** and **metadata** are used by PAIG to enforce access permissions to individual chunks."
      ],
      "metadata": {
        "id": "4f334OlS34pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import CollectionSchema, FieldSchema, DataType\n",
        "\n",
        "COLLECTION_NAME = \"PrivaceraSampleCollection\"\n",
        "\n",
        "def create_collection():\n",
        "    source = FieldSchema(\n",
        "        name=\"source\",\n",
        "        dtype=DataType.VARCHAR,\n",
        "        max_length=65535\n",
        "    )\n",
        "    text = FieldSchema(\n",
        "        name=\"text\",\n",
        "        dtype=DataType.VARCHAR,\n",
        "        max_length=65535\n",
        "    )\n",
        "    pk = FieldSchema(\n",
        "        name=\"pk\",\n",
        "        dtype=DataType.INT64,\n",
        "        is_primary=True,\n",
        "        auto_id=True\n",
        "    )\n",
        "    vector = FieldSchema(\n",
        "        name=\"vector\",\n",
        "        dtype=DataType.FLOAT_VECTOR,\n",
        "        dim=1536\n",
        "    )\n",
        "    # The following columns are used by PAIG for enforcing Fine Grained Access Control\n",
        "    users = FieldSchema(\n",
        "        name=\"users\",\n",
        "        dtype=DataType.ARRAY,\n",
        "        element_type=DataType.VARCHAR,\n",
        "        max_length=65535,\n",
        "        max_capacity=1024\n",
        "    )\n",
        "    groups = FieldSchema(\n",
        "        name=\"groups\",\n",
        "        dtype=DataType.ARRAY,\n",
        "        element_type=DataType.VARCHAR,\n",
        "        max_length=65535,\n",
        "        max_capacity=1024\n",
        "    )\n",
        "    metadata = FieldSchema(\n",
        "        name=\"metadata\",\n",
        "        dtype=DataType.JSON\n",
        "    )\n",
        "\n",
        "    schema = CollectionSchema(\n",
        "        fields=[source, text, pk, vector, users, groups, metadata],\n",
        "        description=\"Sample Privacera Milvus Collection\",\n",
        "        enable_dynamic_field=True\n",
        "    )\n",
        "\n",
        "    from pymilvus import connections\n",
        "    connections.connect(\n",
        "        alias=\"default\",\n",
        "        host=MILVUS_HOST,\n",
        "        port=MILVUS_PORT\n",
        "    )\n",
        "\n",
        "    from pymilvus import Collection\n",
        "\n",
        "    collection = Collection(\n",
        "        name=COLLECTION_NAME,\n",
        "        schema=schema,\n",
        "        using='default'\n",
        "    )\n",
        "\n",
        "    from pymilvus import Collection\n",
        "\n",
        "    collection = Collection(COLLECTION_NAME)\n",
        "\n",
        "    index_params = {\n",
        "        \"index_type\": \"HNSW\",\n",
        "        \"metric_type\": \"L2\",\n",
        "        \"params\": {\n",
        "            \"M\": 10,\n",
        "            \"efConstruction\": 8\n",
        "        }\n",
        "    }\n",
        "\n",
        "    collection.create_index(\n",
        "        field_name=\"vector\",\n",
        "        index_params=index_params,\n",
        "        index_name=\"index\"\n",
        "    )\n",
        "    print(f\"Collection = {COLLECTION_NAME} created\")\n",
        "\n",
        "create_collection()"
      ],
      "metadata": {
        "id": "ba14MlnNwRFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de9571a-2645-44d9-c81e-a7a71f018696"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection = PrivaceraSampleCollection created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Create sample documents in a folder\n",
        "\n",
        "In this notebook, we will create the sample documents dynamically in the local folder named `raw_data` within the Collab. Ideally, these documents should be loaded from appropriate sources.\n",
        "\n",
        "- x10.txt - Contains existing product specification and it is accessible by everyone\n",
        "- x11.txt - Contains the specification of the product which is under development. This is highly classified data and only team members from R&D have access to this file\n",
        "- x10-salesdata.txt - Sales number for the product x10. Only Sales team have access to it.\n",
        "- customer-feedback.txt - Customer feedback which contains PII data. Only few people can access see PII data"
      ],
      "metadata": {
        "id": "rEVwLIFyMMPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def create_raw_data():\n",
        "    raw_data_dir = \"raw_data\"\n",
        "\n",
        "    file_contents = {\n",
        "        \"x10.txt\": \"\"\"\n",
        "Product Specification Sheet of x10\n",
        "Display: Size and resolution - 6.5\" AMOLED, 120Hz refresh rate\n",
        "Processor: Model name  Snapdragon 8 Gen 1\n",
        "RAM: Options 8GB/12GB\n",
        "Storage: Options 128GB/256GB\n",
        "Camera: rear camera system with multiple lenses, front-facing camera\n",
        "Battery: Capacity 5000mAh\n",
        "Operating System: Version Android 13\n",
        "Key Features: long battery life, fast performance, high-quality camera\n",
        "        \"\"\"\n",
        "        , \"x11.txt\": \"\"\"\n",
        "Product Specification Sheet of x11\n",
        "Display: Size and resolution - 7.5\" AMOLED, 360Hz refresh rate\n",
        "Processor: Model name  Snapdragon 10 Gen 3\n",
        "RAM: Options 16GB/24GB\n",
        "Storage: Options 256GB/512GB\n",
        "Camera: 360 camera system with multiple lenses, front-facing camera\n",
        "Battery: Capacity 10000mAh\n",
        "Operating System: Version Android 13\n",
        "Key Features: super long battery life, ultra fast performance, 360 camera\n",
        "        \"\"\"\n",
        "        , \"x10-salesdata.txt\": \"\"\"\n",
        "Sales Data for X10 Model:\n",
        "Monthly Sales Report (Internal)\n",
        "Region\tUnits Sold\tRevenue\n",
        "North America\t20,000\t$10,000,000\n",
        "Europe\t15,000\t$7,500,000\n",
        "Asia Pacific\t10,000\t$5,000,000\n",
        "Total\t45,000\t$22,500,000\n",
        "    \"\"\"\n",
        "        , \"customer-feedback.txt\": \"\"\"\n",
        "Customer Feedback Analysis - X10 Model\n",
        "\n",
        "Positive Feedback for X10 Model:\n",
        "\n",
        "\"The X10's battery life is amazing! I can finally ditch the portable charger.\"\n",
        "\n",
        "Sarah Jones, Busy Professional\n",
        "Email: sarah.jones@samplemail.com\n",
        "Phone: (123) 456-7890\n",
        "\"The camera takes crystal-clear pictures, even in low-light conditions. Perfect for capturing memories on the go!\"\n",
        "\n",
        "David Lee, Travel Blogger\n",
        "Email: david.lee@travelblogger.com\n",
        "Phone: (234) 567-8901\n",
        "\"The phone's design is sleek and feels luxurious in hand. The user interface is user-friendly and easy to navigate, even for non-tech-savvy users like me.\"\n",
        "\n",
        "Emily Garcia, Teacher\n",
        "Email: emily.garcia@schoolmail.com\n",
        "Phone: (345) 678-9012\n",
        "\n",
        "Areas for Improvement for X10 Model:\n",
        "\n",
        "\"The phone is a bit bulky for one-handed use. It can be challenging to reach the top of the screen comfortably.\"\n",
        "\n",
        "Michael Chen, Gamer\n",
        "Email: michael.chen@gamermail.com\n",
        "Phone: (456) 789-0123\n",
        "\"I've encountered a few minor software bugs that require restarting the phone. Hopefully, future updates will address these.\"\n",
        "\n",
        "Olivia Rodriguez, Social Media Manager\n",
        "Email: olivia.rodriguez@socialhub.com\n",
        "Phone: (567) 890-1234\n",
        "\"The current storage options are a bit limiting for someone who stores a lot of photos and videos. A higher storage tier or microSD card support would be ideal.\"\n",
        "\n",
        "William Smith, Content Creator\n",
        "Email: william.smith@creatorhub.com\n",
        "Phone: (678) 901-2345\n",
        "\n",
        "Feature Requests for X10 Model:\n",
        "\n",
        "\"Wireless charging would be a fantastic addition for convenience. No more fumbling with cables!\" (Multiple Users)\n",
        "\"A built-in fingerprint sensor would be a welcome security feature for added peace of mind.\" (Several Users)\n",
        "\"The ability to expand storage with a microSD card would be incredibly helpful for users who need more space.\" (Content Creators & Photographers)\n",
        "\"\"\"\n",
        "    }\n",
        "\n",
        "    os.makedirs(raw_data_dir, exist_ok=True)\n",
        "\n",
        "    for file_path, content in file_contents.items():\n",
        "        file_path_with_dir = raw_data_dir + \"/\" + file_path\n",
        "        with open(file_path_with_dir, 'w') as file:\n",
        "            file.write(content)\n",
        "\n",
        "    print(f\"Files created in {raw_data_dir}\")\n",
        "\n",
        "\n",
        "create_raw_data()"
      ],
      "metadata": {
        "id": "Axt8H7F2Mu9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f91a84c-b2de-4546-9ef4-c743eb8a82a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files created in raw_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Associate metadata with the documents\n",
        "\n",
        "Ideally, the access permissions will be carried from the source document. For this exercise, since we are dynamically creating the files, we will also set up the permissions for the files according to the use cases we want to try out.\n",
        "\n",
        "In this cell, we create a custom loader class called **PrivaceraTextLoader** by extending LangChain's class **TextLoader** that will add additional metadata for each document in the collection. For each document, we have a list of users who are allowed to access the document, a list of groups that are allowed to access the document, and additional metadata such as classification associated with the document.\n",
        "\n",
        "We will use the users, groups, and country attributes to filter the documents based on the user querying the vector database."
      ],
      "metadata": {
        "id": "mPwRbVwo4hKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from typing import Optional, List, Iterator\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Define the permissions and classifications for the files\n",
        "file_metadata = {\n",
        "    \"x10.txt\": {\n",
        "        \"users\": [\"sally\", \"peter\", \"emily\", \"mark\"],\n",
        "        \"groups\": [],\n",
        "        \"metadata\": {\"file_name\": \"x10.txt\"}\n",
        "    },\n",
        "    \"x11.txt\": {\n",
        "        \"users\": [\"mark\", \"peter\"],\n",
        "        \"groups\": [],\n",
        "        \"metadata\": {\"SECURITY_LEVEL\": \"CONFIDENTIAL\", \"file_name\": \"x11.txt\"}\n",
        "    },\n",
        "    \"x10-salesdata.txt\": {\n",
        "        \"users\": [\"sally\"],\n",
        "        \"groups\": [\"Sales\"],\n",
        "        \"metadata\": {\"file_name\": \"x10-salesdata.txt\"}\n",
        "    },\n",
        "    \"customer-feedback.txt\": {\n",
        "        \"users\": [\"emily\", \"sally\", \"peter\", \"mark\"],\n",
        "        \"groups\": [\"Sales\"],\n",
        "        \"metadata\": {\"file_name\": \"customer-feedback.txt\"}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Overload the TextLoader class from LangChain to inject additional metadata\n",
        "class PrivaceraTextLoader(TextLoader):\n",
        "    def __init__(self, file_path: str, encoding: Optional[str] = None, autodetect_encoding: bool = False):\n",
        "        super().__init__(file_path, encoding, autodetect_encoding)\n",
        "        print(f\"inside CustomTextLoader init, file_path={file_path}\")\n",
        "\n",
        "    def lazy_load(self) -> Iterator[Document]:\n",
        "        documents = super().lazy_load()\n",
        "\n",
        "        for doc in documents:\n",
        "            file_name = os.path.basename(self.file_path)\n",
        "            print(f\"lazy_load: file_name={file_name}\")\n",
        "            metadata = file_metadata.get(file_name)\n",
        "            if metadata:\n",
        "              # This instructs LangChain to add these additional meta data\n",
        "              doc.metadata[\"users\"] = file_metadata[file_name][\"users\"]\n",
        "              doc.metadata[\"groups\"] = file_metadata[file_name][\"groups\"]\n",
        "              doc.metadata[\"metadata\"] = file_metadata[file_name][\"metadata\"]\n",
        "\n",
        "            yield doc\n",
        "\n",
        "print(\"PrivaceraTextLoader is ready\")\n"
      ],
      "metadata": {
        "id": "zxNRHlzXOHpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbc9b92-f514-45c2-fbec-f20a3b641e1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PrivaceraTextLoader is ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Load the sample documents into Milvus vector database\n",
        "Now the sample documents are loaded into Milvus vector database using LangChain and OpenAI embedding API."
      ],
      "metadata": {
        "id": "iCw3ApSy7F1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.milvus import Milvus\n",
        "\n",
        "text_loader_kwargs = {'autodetect_encoding': True}\n",
        "# The custom PrivaceraTextLoader is passed here. The loaders can be customized\n",
        "# to meet your requirements\n",
        "loader = DirectoryLoader(\"raw_data\", glob=\"**/*.txt\",\n",
        "                         loader_cls=PrivaceraTextLoader,\n",
        "                         loader_kwargs=text_loader_kwargs)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"len docs = {len(docs)}\")\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(docs)\n",
        "\n",
        "# Create OpenAI Embeddings\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "vector_store = Milvus.from_documents(\n",
        "    docs,\n",
        "    embedding=embeddings,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT}\n",
        ")\n",
        "\n",
        "print(f\"Loaded {len(docs)} into collection {COLLECTION_NAME} successfully.\")"
      ],
      "metadata": {
        "id": "PHs_9nJtxj8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aaeac5f-f666-4f0c-eb26-27637a2f625c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside CustomTextLoader init, file_path=raw_data/x10-salesdata.txt\n",
            "lazy_load: file_name=x10-salesdata.txt\n",
            "inside CustomTextLoader init, file_path=raw_data/x10.txt\n",
            "lazy_load: file_name=x10.txt\n",
            "inside CustomTextLoader init, file_path=raw_data/customer-feedback.txt\n",
            "lazy_load: file_name=customer-feedback.txt\n",
            "inside CustomTextLoader init, file_path=raw_data/x11.txt\n",
            "lazy_load: file_name=x11.txt\n",
            "len docs = 4\n",
            "Loaded 5 into collection PrivaceraSampleCollection successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. LangChain RAG bot\n",
        "\n",
        "This is a simple LangChain application which uses Milvus for VectorDB and PAIG for preventing Data Leakage to unauthorized users\n",
        "\n",
        "Integrating PAIG requires to add couple of lines in your LangChain application. PAIG shield automatically intercepts all calls to RAG/VectorDB and LLM does the validation, guardrails and data filtering.\n",
        "\n",
        "> Note: Look for comment **#PAIG** for the changes that needed to integrate PAIG"
      ],
      "metadata": {
        "id": "R7H1naA_8kU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PAIG: Add the following 2 imports\n",
        "import privacera_shield\n",
        "from privacera_shield import client as privacera_shield_client\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "# Create Milvus vector store\n",
        "vector_store = Milvus(embeddings, COLLECTION_NAME,\n",
        "                      connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT})\n",
        "\n",
        "# expose this index in a retriever interface\n",
        "milvus_retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity\", search_kwargs={\"k\": 100}\n",
        ")\n",
        "\n",
        "# PAIG: Add the below line to initialize Privacera Shield with milvus and\n",
        "#       langchain. This needs to be done only one time and the PAIG config file needs\n",
        "#       to be passed to it. The config contains the shared secret and URL to PAIG\n",
        "#       server to get the policies and send the audit logs\n",
        "privacera_shield_client.setup(frameworks=[\"milvus\", \"langchain\"], application_config=app_config_file_content)\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=openai_api_key, model_name=\"gpt-3.5-turbo\")\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "\n",
        "def query_as_user(username, query):\n",
        "    print(f\"Prompt: {query}\")\n",
        "    print()\n",
        "\n",
        "    memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=3)\n",
        "\n",
        "    llm_chain = ConversationalRetrievalChain.from_llm(llm=llm,\n",
        "                                                      retriever=milvus_retriever,\n",
        "                                                      memory=memory,\n",
        "                                                      verbose=False)\n",
        "    try:\n",
        "#PAIG: Before LangChain invoke is called, set the PAIG context with the user who\n",
        "#      is making the call\n",
        "        with privacera_shield_client.create_shield_context(username=username):\n",
        "            response = llm_chain.invoke({\"question\": query})\n",
        "            print(\"LLM Response:\")\n",
        "            print(f\"{response.get('answer')}\")\n",
        "            #wrap_text(f\"{response.get('answer')}\")\n",
        "#PAIG: This is to handle access denied to the GenAI application or if the user\n",
        "#      passed unappropriate or unauthorized contents in the prompt or if reply\n",
        "#      contain unappropriate or unauthorized contents\n",
        "    except privacera_shield.exception.AccessControlException as e:\n",
        "        # If access is denied, then this exception will be thrown. You can handle it accordingly.\n",
        "        print(f\"AccessControlException: {e}\")\n",
        "\n",
        "# utility function to wrap the output\n",
        "def wrap_text(text, width=80):\n",
        "    words = text.split()\n",
        "    character_count = 0\n",
        "    for word in words:\n",
        "        if character_count + len(word) + 1 > width:  # Check if adding the word would exceed the width\n",
        "            print(\"\\n\", end=\"\")  # Start a new line\n",
        "            character_count = 0  # Reset the character count for the new line\n",
        "        print(word, end=\" \")  # Print the word followed by a space\n",
        "        character_count += len(word) + 1  # Update the character count\n",
        "\n",
        "print(\"RAG Bot is ready\")"
      ],
      "metadata": {
        "id": "BVBorz6S1mNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f6694f-bbc7-441a-ea62-700fb60d1614"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG Bot is ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Ask question about the product X11 which is under development\n",
        "\n",
        "\n",
        "Peter belongs to the R&D team and has access to details of unreleased product called X11. And he should be able to compare all the phone models.\n",
        "\n",
        "Sally belongs to the Sales team and she doesn't have access to details of X11 and she shouldn't be able to compare the phone models\n",
        "\n",
        "> Note: We explcitly passing the username. Ideally this would be the logged in user"
      ],
      "metadata": {
        "id": "KnprAOe9Xrwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"peter\", \"Compare the product specifications for X10 and X11\")\n",
        "# this will compare both the product names"
      ],
      "metadata": {
        "id": "Gz-DFLGRQ0l_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfcb87c-6392-4815-c74b-b515e43ab75e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Compare the product specifications for X10 and X11\n",
            "\n",
            "LLM Response:\n",
            "The product specifications for X10 and X11 are as follows:\n",
            "\n",
            "**X10 Model:**\n",
            "- Display: 6.5\" AMOLED, 120Hz refresh rate\n",
            "- Processor: Snapdragon 8 Gen 1\n",
            "- RAM: Options 8GB/12GB\n",
            "- Storage: Options 128GB/256GB\n",
            "- Camera: Rear camera system with multiple lenses, front-facing camera\n",
            "- Battery: Capacity 5000mAh\n",
            "- Operating System: Android 13\n",
            "- Key Features: Long battery life, fast performance, high-quality camera\n",
            "\n",
            "**X11 Model:**\n",
            "- Display: 7.5\" AMOLED, 360Hz refresh rate\n",
            "- Processor: Snapdragon 10 Gen 3\n",
            "- RAM: Options 16GB/24GB\n",
            "- Storage: Options 256GB/512GB\n",
            "- Camera: 360 camera system with multiple lenses, front-facing camera\n",
            "- Battery: Capacity 10000mAh\n",
            "- Operating System: Android 13\n",
            "- Key Features: Super long battery life, ultra-fast performance, 360 camera\n",
            "\n",
            "In summary, the X11 model has a larger display with a higher refresh rate, a more powerful processor, larger RAM and storage options, a higher capacity battery, and unique features like a 360 camera system compared to the X10 model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"sally\", \"Compare the product specifications for X10 and X11\")\n",
        "# since Sally doesn't have access to new development, she won't be able to compare the models"
      ],
      "metadata": {
        "id": "bpW7i6vgX5xM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dece896e-9aeb-436c-ab9d-cdcca2f61a20"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Compare the product specifications for X10 and X11\n",
            "\n",
            "LLM Response:\n",
            "I don't have information about the product specifications for the X11 model to compare it with the X10 model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Check Audit logs\n",
        "\n",
        "1. In PAIG portal, go to **Security**->**Access Audits**\n",
        "2. Click on the **eye** icon for peter's request. You should see the sequence of events, you expand all to the contexts that were retrieved from VectorDB. You should see the documents from X10 and X11\n",
        "3. Similarly you can see the audit record for **sally** and in the **Context Documents** you won't any reference to X11 documents\n",
        "\n",
        "This demonstrates that for the same prompt, based on the user who is asking, the response will be different based on the documents the user has access to it. This prevents unintentional data leakages when documents are stored centrally from multiple data sources with different access controls"
      ],
      "metadata": {
        "id": "dhQgZH0KBict"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Ask sales details by members of Sales and other teams\n",
        "\n",
        "Sally belongs to the Sales team and she has access to the sales numbers.\n",
        "\n",
        "Peter belonging to the R&D doesn't have access sales data.\n",
        "\n",
        "Only the sales team has access to sales documents and these are carried forward in the VectorDB and enforced there"
      ],
      "metadata": {
        "id": "n3AD3UIMYAGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"sally\", \"Give me the monthly sales data for X10?\")"
      ],
      "metadata": {
        "id": "IqGwjVtpYEJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d870b10c-de20-4456-c9fe-15cddb86a9e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Give me the monthly sales data for X10?\n",
            "\n",
            "LLM Response:\n",
            "The monthly sales data for the X10 model is as follows:\n",
            "- North America: 20,000 units sold, $10,000,000 revenue\n",
            "- Europe: 15,000 units sold, $7,500,000 revenue\n",
            "- Asia Pacific: 10,000 units sold, $5,000,000 revenue\n",
            "- Total: 45,000 units sold, $22,500,000 revenue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"peter\", \"Give me the monthly sales data for X10?\")"
      ],
      "metadata": {
        "id": "oIMtUmjBYDoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b9a5da-f780-43b8-a70f-26bdf8a18d75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Give me the monthly sales data for X10?\n",
            "\n",
            "LLM Response:\n",
            "I don't have access to specific sales data for the X10 model. It would be best to check with the company or retailer directly for monthly sales figures.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Let's redact PII data based on policy\n",
        "Sally belongs to the Sales team and she can see customer details\n",
        "\n",
        "Peter belonging to the R&D can't see customer PII data, but can see the feedback.\n",
        "\n",
        "1. Go to **Application -> AI Applications** and select the **AI Application** you created\n",
        "2. Now select the **PERMISSIONS** tab\n",
        "3. Click the pencil for the **Personal Identifier Redaction** policy\n",
        "1. Remove **Everyone** and add **peter**\n",
        "1. On the right side for **Prompt** select the dropdown value **Allow**\n",
        "1. Leave the **Reply** as **Redact**\n",
        "1. Save the policy\n",
        "1. Now **Enable** the policy by toggling **Status** toggle\n"
      ],
      "metadata": {
        "id": "nRxE9xY0YJaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"sally\", \"Give me the feedbacks and their contact information\")"
      ],
      "metadata": {
        "id": "W37s1s63YV_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f3f8db-64f4-4238-bfa4-04021b66a51e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Give me the feedbacks and their contact information\n",
            "\n",
            "LLM Response:\n",
            "Sure! Here is the feedback and contact information for the X10 model:\n",
            "\n",
            "Positive Feedback:\n",
            "1. Sarah Jones, Busy Professional\n",
            "Feedback: The X10's battery life is amazing! I can finally ditch the portable charger.\n",
            "Contact: Email - sarah.jones@samplemail.com, Phone - (123) 456-7890\n",
            "\n",
            "2. David Lee, Travel Blogger\n",
            "Feedback: The camera takes crystal-clear pictures, even in low-light conditions. Perfect for capturing memories on the go!\n",
            "Contact: Email - david.lee@travelblogger.com, Phone - (234) 567-8901\n",
            "\n",
            "3. Emily Garcia, Teacher\n",
            "Feedback: The phone's design is sleek and feels luxurious in hand. The user interface is user-friendly and easy to navigate, even for non-tech-savvy users like me.\n",
            "Contact: Email - emily.garcia@schoolmail.com, Phone - (345) 678-9012\n",
            "\n",
            "Areas for Improvement:\n",
            "1. Michael Chen, Gamer\n",
            "Feedback: The phone is a bit bulky for one-handed use. It can be challenging to reach the top of the screen comfortably.\n",
            "Contact: Email - michael.chen@gamermail.com, Phone - (456) 789-0123\n",
            "\n",
            "2. Olivia Rodriguez, Social Media Manager\n",
            "Feedback: I've encountered a few minor software bugs that require restarting the phone. Hopefully, future updates will address these.\n",
            "Contact: Email - olivia.rodriguez@socialhub.com, Phone - (567) 890-1234\n",
            "\n",
            "3. William Smith, Content Creator\n",
            "Feedback: The current storage options are a bit limiting for someone who stores a lot of photos and videos. A higher storage tier or microSD card support would be ideal.\n",
            "Contact: Email - william.smith@creatorhub.com, Phone - (678) 901-2345\n",
            "\n",
            "Please let me know if you need more information!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_as_user(\"peter\", \"Give me the feedbacks and their contact information\")"
      ],
      "metadata": {
        "id": "_3CDgb7dYX86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3455064-a811-4aad-fec7-2515b4e055d3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Give me the feedbacks and their contact information\n",
            "\n",
            "LLM Response:\n",
            "Sure! Here is the feedback provided for the X10 model along with the contact information of the customers who provided the feedback:\n",
            "\n",
            "Positive Feedback for X10 Model:\n",
            "1. <<PERSON>>, Busy Professional\n",
            "   Email: <<EMAIL_ADDRESS>>\n",
            "   Phone: <<PHONE_NUMBER>>\n",
            "   Feedback: \"The X10's battery life is amazing! I can finally ditch the portable charger.\"\n",
            "\n",
            "2. <<PERSON>>, Travel Blogger\n",
            "   Email: <<EMAIL_ADDRESS>>\n",
            "   Phone: <<PHONE_NUMBER>>\n",
            "   Feedback: \"The camera takes crystal-clear pictures, even in low-light conditions. Perfect for capturing memories on the go!\"\n",
            "\n",
            "3. <<PERSON>>, Teacher\n",
            "   Email: <<EMAIL_ADDRESS>>\n",
            "   Phone: <<PHONE_NUMBER>>\n",
            "   Feedback: \"The phone's design is sleek and feels luxurious in hand. The user interface is user-friendly and easy to navigate, even for non-tech-savvy users like me.\"\n",
            "\n",
            "Areas for Improvement for X10 Model:\n",
            "1. <<PERSON>>, <<PERSON>>\n",
            "   Email: <<EMAIL_ADDRESS>>\n",
            "   Phone: (456) 789-0123\n",
            "   Feedback: \"The phone is a bit bulky for one-handed use. It can be challenging to reach the top of the screen comfortably.\"\n",
            "\n",
            "2. <<PERSON>>, Social Media Manager\n",
            "   Email: <<EMAIL_ADDRESS>>\n",
            "   Phone: <<PHONE_NUMBER>>\n",
            "   Feedback: \"I've encountered a few minor software bugs that require restarting the phone. Hopefully, future updates will address these.\"\n",
            "\n",
            "3. <<PERSON>>, Content Creator\n",
            "   Email: <<EMAIL_ADDRESS>>\n",
            "   Phone: <<PHONE_NUMBER>>\n",
            "   Feedback: \"The current storage options are a bit limiting for someone who stores a lot of photos and videos. A higher storage tier or microSD card support would be ideal.\"\n",
            "\n",
            "I hope this helps!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Check Audits Logs\n",
        "\n",
        "For this prompts and replies also you can check the access audit logs. You will see that even though the LLM responded with the PII information, since peter shouldn't be having access to PII data, they will redacted. This ensure appropriate privacy and compliance requirements are enforced"
      ],
      "metadata": {
        "id": "9Bg3mnMCFImw"
      }
    }
  ]
}
